{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "For my neural network, i use tensorflow as backend, so in jupyter, you need to install tensorflow environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data from iris dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1:\n",
    "1. get the data which is related to the column 0 to 4\n",
    "2. encode the class attribute, which is Iris-setosa=>0,Iris-versicolor=>1, Iris-virginica=>2, because the class label is object so i need to change it\n",
    "3. Because we have three different class, so we use (0,0,1),(0,1,0),(1,0,0) to represent three class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('C:\\\\Users\\\\WesleyZhou\\\\Desktop\\\\CS559\\\\Assignment3\\\\iris.txt', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [0,1,2,3]\n",
    "X = data[cols].values\n",
    "y = data[4].values\n",
    "\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "label_encoder.fit(data[4])\n",
    "y = label_encoder.transform(data[4])\n",
    "y = keras.utils.to_categorical(y, num_classes=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2:\n",
    "construct my neural network, which has 4 input follow the iris dataset, and one input layer with 500 units,two hidden layers with 300 and 100 units, and one output layer with 3 units, which represent the 000,010,001 the class in iris dataset\n",
    "\n",
    "we use 5-fold, so we can calculate the accuracy using evaluate method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "120/120 [==============================] - 1s 10ms/step - loss: 0.9842 - acc: 0.4083\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 0s 341us/step - loss: 0.7809 - acc: 0.5000\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 0s 341us/step - loss: 0.6698 - acc: 0.6417\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 0s 399us/step - loss: 0.5442 - acc: 0.8000\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 0s 316us/step - loss: 0.4280 - acc: 0.9000\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 0s 324us/step - loss: 0.3675 - acc: 0.9250\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 0s 329us/step - loss: 0.3461 - acc: 0.8583\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 0s 266us/step - loss: 0.2652 - acc: 0.9167\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 0s 266us/step - loss: 0.2254 - acc: 0.9250\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 0s 342us/step - loss: 0.2062 - acc: 0.9333\n",
      "120/120 [==============================] - 0s 382us/step\n",
      "30/30 [==============================] - 0s 63us/step\n",
      "Epoch 1/10\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.9837 - acc: 0.4167\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 0s 349us/step - loss: 0.7225 - acc: 0.6417\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 0s 268us/step - loss: 0.5569 - acc: 0.7167\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 0s 316us/step - loss: 0.4207 - acc: 0.9583\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 0s 310us/step - loss: 0.3677 - acc: 0.8500\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 0s 357us/step - loss: 0.2685 - acc: 0.9250\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 0s 300us/step - loss: 0.2300 - acc: 0.9333\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 0s 366us/step - loss: 0.2513 - acc: 0.9000\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 0s 357us/step - loss: 0.1689 - acc: 0.9417\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 0s 399us/step - loss: 0.1643 - acc: 0.9500\n",
      "120/120 [==============================] - 0s 515us/step\n",
      "30/30 [==============================] - 0s 60us/step\n",
      "Epoch 1/10\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.9177 - acc: 0.6750\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 0s 249us/step - loss: 0.5393 - acc: 0.8333\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 0s 374us/step - loss: 0.3550 - acc: 0.8333\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 0s 333us/step - loss: 0.2798 - acc: 0.8750\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 0s 341us/step - loss: 0.2010 - acc: 0.8917\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 0s 391us/step - loss: 0.1515 - acc: 0.9750\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 0s 357us/step - loss: 0.1225 - acc: 0.9833\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 0s 381us/step - loss: 0.1142 - acc: 0.9583\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 0s 274us/step - loss: 0.0919 - acc: 0.9917\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 0s 291us/step - loss: 0.0898 - acc: 0.9667\n",
      "120/120 [==============================] - 0s 824us/step\n",
      "30/30 [==============================] - 0s 75us/step\n",
      "Epoch 1/10\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.9072 - acc: 0.5917\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 0s 224us/step - loss: 0.6120 - acc: 0.7583\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 0s 324us/step - loss: 0.4292 - acc: 0.8333\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 0s 274us/step - loss: 0.3623 - acc: 0.8500\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 0s 291us/step - loss: 0.2972 - acc: 0.8500\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 0s 374us/step - loss: 0.2731 - acc: 0.8667\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 0s 357us/step - loss: 0.2664 - acc: 0.8750\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 0s 303us/step - loss: 0.2581 - acc: 0.8667\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 0s 299us/step - loss: 0.2007 - acc: 0.9167\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 0s 366us/step - loss: 0.1713 - acc: 0.9333\n",
      "120/120 [==============================] - 0s 892us/step\n",
      "30/30 [==============================] - 0s 67us/step\n",
      "Epoch 1/10\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.8853 - acc: 0.7667\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 0s 208us/step - loss: 0.6107 - acc: 0.7750\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 0s 332us/step - loss: 0.3971 - acc: 0.8333\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 0s 278us/step - loss: 0.2918 - acc: 0.9250\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 0s 366us/step - loss: 0.2469 - acc: 0.9000\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 0s 319us/step - loss: 0.2123 - acc: 0.9083\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 0s 305us/step - loss: 0.1316 - acc: 0.9750\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 0s 281us/step - loss: 0.1220 - acc: 0.9750\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 0s 259us/step - loss: 0.1041 - acc: 0.9833\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 0s 322us/step - loss: 0.0782 - acc: 0.9833\n",
      "120/120 [==============================] - 0s 1ms/step\n",
      "30/30 [==============================] - 0s 100us/step\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "scores_train = []\n",
    "scores_test = []\n",
    "for train, test in kf.split(X, y):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = 500,input_dim = 4,kernel_initializer ='normal',activation='relu'))\n",
    "    model.add(Dense(units = 300,activation='relu'))\n",
    "    model.add(Dense(units = 100,activation='relu'))\n",
    "    model.add(Dense(units = 3,activation = 'softmax'))\n",
    "    model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    \n",
    "    model.fit(X[train], y[train], epochs=10, batch_size=20, verbose=1)\n",
    "    \n",
    "    score_train = model.evaluate(X[train],y[train], verbose = 1)\n",
    "    score_test = model.evaluate(X[test], y[test], verbose = 1)\n",
    "    \n",
    "    scores_train.append(score_train[1]*100)\n",
    "    scores_test.append(score_test[1]*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3:\n",
    "see the score of train and test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores_train: [96.666666666666671, 97.500000397364289, 100.0, 97.5, 98.333332935969025]\n",
      "score_test: [100.0, 100.0, 80.000001192092896, 100.0, 63.333332538604736]\n"
     ]
    }
   ],
   "source": [
    "print(\"scores_train:\",scores_train)\n",
    "print(\"score_test:\",scores_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
